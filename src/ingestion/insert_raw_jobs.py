import logging
from config.config_loader import load_config
import psycopg2
import csv
import os

from utils.logger import get_logger

logger = get_logger(__name__)

INSERT_QUERY = """
INSERT INTO raw_jobs (title, company, description, time_posted, date_crawled)
VALUES (%s, %s, %s, %s, %s)
ON CONFLICT (title, company, date_crawled) DO NOTHING;
"""

def import_csv_to_db():
    logger.info("üöÄ B·∫Øt ƒë·∫ßu import d·ªØ li·ªáu t·ª´ CSV v√†o PostgreSQL")
    config = load_config()
    db_config = config["database"]
    csv_file_path = config["crawling"]["csv_output_path"]

    if not os.path.exists(csv_file_path):
        logger.warning(f"‚ö†Ô∏è File CSV kh√¥ng t·ªìn t·∫°i: {csv_file_path}")
        return

    try:
        conn = psycopg2.connect(**db_config)
        cursor = conn.cursor()
        logger.info("‚úÖ ƒê√£ k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu th√†nh c√¥ng")

        with open(csv_file_path, newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                values = (
                    row['title'],
                    row['company'],
                    row['description'],
                    row['time_posted'],
                    row['date_crawled']
                )
                try:
                    cursor.execute(INSERT_QUERY, values)
                    conn.commit()
                    logger.debug(f"üì• Inserted: {row['title']} - {row['company']}")
                except Exception as e:
                    conn.rollback()
                    logger.error(f"‚ùå L·ªói khi insert: {e}")

        cursor.close()
        conn.close()
        logger.info("‚úÖ ƒê√£ ho√†n th√†nh import d·ªØ li·ªáu")

    except Exception as e:
        logger.exception(f"‚ùå Kh√¥ng th·ªÉ k·∫øt n·ªëi c∆° s·ªü d·ªØ li·ªáu: {e}")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    import_csv_to_db()
