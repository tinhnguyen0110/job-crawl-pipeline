executor: "KubernetesExecutor"

images:
  airflow:
    repository: asia-southeast1-docker.pkg.dev/alpine-figure-461007-i9/crawl2insight-repo/airflow
    # repository: apache/airflow
    tag: g-d5b80f5
    pullPolicy: Always
 
extraEnv: |-
  - name: AIRFLOW__SECRETS__BACKEND
    value: airflow.providers.google.cloud.secrets.secret_manager.CloudSecretManagerBackend
  - name: AIRFLOW__SECRETS__BACKEND_KWARGS
    value: '{"project_id": "alpine-figure-461007-i9", "connections_prefix": "airflow-connections", "variables_prefix": "airflow-variables"}'

serviceAccount:
  create: false
  name: airflow-ksa

scheduler:
  serviceAccount:
    create: false
    name: airflow-ksa

webserver:
  serviceAccount:
      create: false
      name: airflow-ksa
  startupProbe:
    failureThreshold: 30        # TƒÉng s·ªë l·∫ßn th·ª≠
    periodSeconds: 10           # C√°ch nhau 10 gi√¢y
    initialDelaySeconds: 60     # ƒê·ª£i 30s r·ªìi m·ªõi b·∫Øt ƒë·∫ßu probe
    timeoutSeconds: 5           # Timeout m·ªói l·∫ßn th·ª≠
  livenessProbe:
    initialDelaySeconds: 60
    failureThreshold: 10
  resources:
    limits:
      cpu: "1"       # Gi·ªõi h·∫°n t·ªëi ƒëa 1 core CPU
      memory: "2Gi"  # Gi·ªõi h·∫°n t·ªëi ƒëa 2 Gigabytes Memory
    requests:
      cpu: "500m"    # Y√™u c·∫ßu ban ƒë·∫ßu 0.5 core CPU
      memory: "1Gi"  # Y√™u c·∫ßu ban ƒë·∫ßu 1 Gigabyte Memory
  

triggerer:
  serviceAccount:
    create: false
    name: airflow-ksa
  persistence:
    enabled: true
    size: 5Gi              # üëà Gi·∫£m l·∫°i t·ª´ 100Gi
    accessMode: ReadWriteOnce
    storageClass: standard


extraPipPackages:
  - dateparser
  - playwright


dags:
  persistence:
      enabled: false 
  gitSync:
    enabled: true
    repo: git@github.com:tinhnguyen0110/job-crawl-pipeline.git
    branch: main
    subPath: airflow/dags  # th∆∞ m·ª•c ch·ª©a DAGs trong repo
    depth: 1
    wait: 10
    sshKeySecret: gitsync-ssh-key
    rev: HEAD

logs:
  persistence:
    enabled: false

config:
  kubernetes:
    delete_worker_pods: True
  logging:
    remote_logging: "True"
    remote_base_log_folder: "gs://airflow-logs-tinhnv-gke/logs"
    remote_log_conn_id: "google_cloud_default"

# postgresql:
#   enabled: true
#   persistence:
#       accessModes:
#         - ReadWriteOnce

workers:
  serviceAccount:
    create: false
    name: airflow-ksa
  extraContainers:
    - name: cloud-sql-proxy
      image: "gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.10.0"
      args:
      - "--structured-logs"
      - "--port=5432"
      - "alpine-figure-461007-i9:asia-southeast1:job-pipeline-db"
      securityContext:
        runAsNonRoot: true


postgresql:
  enabled: false

# T·∫Øt sub-chart redis
redis:
  enabled: false

# C·∫•u h√¨nh ƒë·ªÉ k·∫øt n·ªëi ƒë·∫øn DB v√† Redis b√™n ngo√†i
data:
  # C·∫•u h√¨nh k·∫øt n·ªëi ƒë·∫øn Metadata Database (PostgreSQL)
  metadataConnection:
    protocol: "postgresql"
    # User v√† DB ƒë√£ ƒë∆∞·ª£c t·∫°o b·ªüi initdbScripts c·ªßa PostgreSQL
    user: "airflow_user"
    db: "airflow_db"
    # M·∫≠t kh·∫©u n√†y ph·∫£i kh·ªõp v·ªõi m·∫≠t kh·∫©u b·∫°n ƒë√£ t·∫°o trong initdbScripts
    pass: "airflow123" 
    # Host l√† service c·ªßa PostgreSQL d√πng chung
    host: "postgresql-shared-hl.platform-services.svc.cluster.local"
    port: 5432

  resultBackendConnection:
    user: airflow_user
    pass: "airflow123"
    protocol: postgresql
    host: postgresql-shared-hl.platform-services.svc.cluster.local
    port: 5432
    db: airflow_db
    sslmode: disable
  # C·∫•u h√¨nh k·∫øt n·ªëi ƒë·∫øn Result Backend (c≈©ng l√† PostgreSQL)
  # C·∫•u h√¨nh k·∫øt n·ªëi ƒë·∫øn Broker (Redis)
  # Ch√∫ng ta s·∫Ω cung c·∫•p th·∫≥ng chu·ªói k·∫øt n·ªëi brokerUrl
  # ƒê·ªãnh d·∫°ng: redis://:<password>@<host>:<port>/<db_number>
  brokerUrl: "redis://:YourStrongRedisPassword@redis-shared-master.platform-services.svc.cluster.local:6379/1"
    