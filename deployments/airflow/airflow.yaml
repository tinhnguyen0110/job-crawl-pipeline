executor: "KubernetesExecutor"

images:
  airflow:
    repository: asia-southeast1-docker.pkg.dev/alpine-figure-461007-i9/crawl2insight-repo/airflow
    # repository: apache/airflow
    tag: g-d5b80f5
    pullPolicy: Always
 
extraEnv: |-
  - name: AIRFLOW__SECRETS__BACKEND
    value: airflow.providers.google.cloud.secrets.secret_manager.CloudSecretManagerBackend
  - name: AIRFLOW__SECRETS__BACKEND_KWARGS
    value: '{"project_id": "alpine-figure-461007-i9", "connections_prefix": "airflow-connections", "variables_prefix": "airflow-variables"}'

serviceAccount:
  create: false
  name: airflow-ksa

scheduler:
  serviceAccount:
    create: false
    name: airflow-ksa

webserver:
  serviceAccount:
      create: false
      name: airflow-ksa
  startupProbe:
    failureThreshold: 30        # Tăng số lần thử
    periodSeconds: 10           # Cách nhau 10 giây
    initialDelaySeconds: 60     # Đợi 30s rồi mới bắt đầu probe
    timeoutSeconds: 5           # Timeout mỗi lần thử
  livenessProbe:
    initialDelaySeconds: 60
    failureThreshold: 10
  resources:
    limits:
      cpu: "1"       # Giới hạn tối đa 1 core CPU
      memory: "2Gi"  # Giới hạn tối đa 2 Gigabytes Memory
    requests:
      cpu: "500m"    # Yêu cầu ban đầu 0.5 core CPU
      memory: "1Gi"  # Yêu cầu ban đầu 1 Gigabyte Memory
  

triggerer:
  serviceAccount:
    create: false
    name: airflow-ksa


extraPipPackages:
  - dateparser
  - playwright


dags:
  persistence:
      enabled: false 
  gitSync:
    enabled: true
    repo: git@github.com:tinhnguyen0110/job-crawl-pipeline.git
    branch: main
    subPath: airflow/dags  # thư mục chứa DAGs trong repo
    depth: 1
    wait: 10
    sshKeySecret: gitsync-ssh-key
    rev: HEAD

logs:
  persistence:
    enabled: false

config:
  kubernetes:
    delete_worker_pods: True
  logging:
    remote_logging: "True"
    remote_base_log_folder: "gs://airflow-logs-tinhnv-gke/logs"
    remote_log_conn_id: "google_cloud_default"

# postgresql:
#   enabled: true
#   persistence:
#       accessModes:
#         - ReadWriteOnce

workers:
  serviceAccount:
    create: false
    name: airflow-ksa
  extraContainers:
    - name: cloud-sql-proxy
      image: "gcr.io/cloud-sql-connectors/cloud-sql-proxy:2.10.0"
      args:
      - "--structured-logs"
      - "--port=5432"
      - "alpine-figure-461007-i9:asia-southeast1:job-pipeline-db"
      securityContext:
        runAsNonRoot: true


postgresql:
  enabled: false

# Tắt sub-chart redis
redis:
  enabled: false

# Cấu hình để kết nối đến DB và Redis bên ngoài
data:
  # Cấu hình kết nối đến Metadata Database (PostgreSQL)
  metadataConnection:
    protocol: "postgresql"
    # User và DB đã được tạo bởi initdbScripts của PostgreSQL
    user: "airflow_user"
    db: "airflow_db"
    # Mật khẩu này phải khớp với mật khẩu bạn đã tạo trong initdbScripts
    pass: "airflow123" 
    # Host là service của PostgreSQL dùng chung
    host: "postgresql-shared-hl.platform-services.svc.cluster.local"
    port: 5432

  resultBackendConnection:
    user: airflow_user
    pass: "airflow123"
    protocol: postgresql
    host: postgresql-shared-hl.platform-services.svc.cluster.local
    port: 5432
    db: airflow_db
    sslmode: disable
  # Cấu hình kết nối đến Result Backend (cũng là PostgreSQL)
  # Cấu hình kết nối đến Broker (Redis)
  # Chúng ta sẽ cung cấp thẳng chuỗi kết nối brokerUrl
  # Định dạng: redis://:<password>@<host>:<port>/<db_number>
  brokerUrl: "redis://:YourStrongRedisPassword@redis-shared-master.platform-services.svc.cluster.local:6379/1"
    

